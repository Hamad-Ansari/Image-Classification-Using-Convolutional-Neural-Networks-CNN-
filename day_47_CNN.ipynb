{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c9224d",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN)\n",
    "A Convolutional Neural Network (CNN) is a specialized class of deep neural networks designed to process grid-structured data, most commonly images. CNNs automatically learn spatial hierarchies of features—from low-level patterns (edges, textures) to high-level concepts (objects, faces).\n",
    "\n",
    "From a data science perspective, CNNs are powerful because they:\n",
    "\n",
    "- Reduce manual feature engineering\n",
    "\n",
    "- Preserve spatial relationships\n",
    "\n",
    "- Scale well to high-dimensional inputs (e.g., images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92182947",
   "metadata": {},
   "source": [
    "Why CNNs Instead of Fully Connected Networks?\n",
    "\n",
    "Consider a 224×224 RGB image:\n",
    "\n",
    "-  Input size = 224 × 224 × 3 ≈ 150,000 features\n",
    "\n",
    "- A fully connected layer would require millions of parameters\n",
    "\n",
    "CNNs solve this problem using:\n",
    "\n",
    "- Local connectivity\n",
    "\n",
    "- Parameter sharing\n",
    "\n",
    "- Down-sampling\n",
    "\n",
    "This makes CNNs computationally efficient and less prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11267f6f",
   "metadata": {},
   "source": [
    "Typical CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078febee",
   "metadata": {},
   "source": [
    "```mathematical\n",
    "Input Image\n",
    "   ↓\n",
    "Convolution + ReLU\n",
    "   ↓\n",
    "Pooling\n",
    "   ↓\n",
    "Convolution + ReLU\n",
    "   ↓\n",
    "Pooling\n",
    "   ↓\n",
    "Flatten\n",
    "   ↓\n",
    "Dense Layer\n",
    "   ↓\n",
    "Softmax Output\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637e845",
   "metadata": {},
   "source": [
    "Example of CNN Data (Image Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4144ed94",
   "metadata": {},
   "source": [
    "| Property   | Value            |\n",
    "| ---------- | ---------------- |\n",
    "| Data type  | Grayscale images |\n",
    "| Image size | 28 × 28          |\n",
    "| Classes    | Digits (0–9)     |\n",
    "| Samples    | 70,000           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3666547e",
   "metadata": {},
   "source": [
    "## Practical CNN Example in Python (MNIST)\n",
    "Practical CNN Example in Python (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bfd5a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1us/step\n",
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(X_train.shape)  # (60000, 28, 28)\n",
    "print(y_train.shape)  # (60000,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd46f2f1",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29681cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Reshape for CNN\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b540db4c",
   "metadata": {},
   "source": [
    "## Build CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ca6a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hammad\\.conda\\envs\\Tensorflow_env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b910c394",
   "metadata": {},
   "source": [
    "## Compile and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f972ac6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9575 - loss: 0.1355 - val_accuracy: 0.9818 - val_loss: 0.0635\n",
      "Epoch 2/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0445 - val_accuracy: 0.9893 - val_loss: 0.0349\n",
      "Epoch 3/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9908 - loss: 0.0295 - val_accuracy: 0.9903 - val_loss: 0.0368\n",
      "Epoch 4/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9928 - loss: 0.0219 - val_accuracy: 0.9880 - val_loss: 0.0474\n",
      "Epoch 5/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0151 - val_accuracy: 0.9905 - val_loss: 0.0399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x209cf1b4830>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556dbb6",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2165369f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0377\n",
      "Test Accuracy: 0.9883999824523926\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
